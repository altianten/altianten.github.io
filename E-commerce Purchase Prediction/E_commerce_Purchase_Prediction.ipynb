{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install catboost shap optuna\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "# Ultra-strong pattern generation\n",
        "def generate_synthetic_data(n_samples=100000):\n",
        "    np.random.seed(42)\n",
        "    print(f\"Generating {n_samples} samples with ultra-strong patterns...\")\n",
        "\n",
        "    # Generate data in chunks\n",
        "    chunk_size = n_samples // 10\n",
        "    dfs = []\n",
        "\n",
        "    for i in range(10):\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = (i + 1) * chunk_size if i < 9 else n_samples\n",
        "\n",
        "        data = {\n",
        "            'customer_id': range(start_idx + 1, end_idx + 1),\n",
        "            'age': np.random.randint(18, 70, end_idx - start_idx),\n",
        "            'gender': np.random.choice(['Male', 'Female', 'Other'], end_idx - start_idx, p=[0.48, 0.48, 0.04]),\n",
        "            'location': np.random.choice(['Urban', 'Suburban', 'Rural'], end_idx - start_idx, p=[0.5, 0.3, 0.2]),\n",
        "            'device_type': np.random.choice(['Desktop', 'Mobile', 'Tablet'], end_idx - start_idx, p=[0.4, 0.5, 0.1]),\n",
        "            'session_duration': np.random.exponential(8, end_idx - start_idx).clip(0.5, 60),\n",
        "            'pages_viewed': np.random.poisson(5, end_idx - start_idx).clip(1, 20),\n",
        "            'cart_items': np.random.poisson(2, end_idx - start_idx).clip(0, 10),\n",
        "            'previous_purchases': np.random.poisson(3, end_idx - start_idx).clip(0, 15),\n",
        "            'time_on_site': np.random.exponential(12, end_idx - start_idx).clip(1, 120),\n",
        "            'discount_applied': np.random.choice([0, 1], end_idx - start_idx, p=[0.7, 0.3]),\n",
        "            'customer_rating': np.random.normal(4, 1, end_idx - start_idx).clip(1, 5),\n",
        "            'purchase': np.zeros(end_idx - start_idx)\n",
        "        }\n",
        "\n",
        "        chunk_df = pd.DataFrame(data)\n",
        "\n",
        "        # Create ultra-strong deterministic patterns\n",
        "        # These patterns are almost deterministic with minimal exceptions\n",
        "\n",
        "        # Pattern 1: Ultra high engagement (98% purchase rate)\n",
        "        ultra_high_engagement = (chunk_df['session_duration'] > 20) & (chunk_df['pages_viewed'] > 15)\n",
        "        chunk_df.loc[ultra_high_engagement, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 2: Discount with full cart (99% purchase rate)\n",
        "        discount_full_cart = (chunk_df['discount_applied'] == 1) & (chunk_df['cart_items'] >= 5)\n",
        "        chunk_df.loc[discount_full_cart, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 3: Premium customers (99% purchase rate)\n",
        "        premium_customers = (chunk_df['previous_purchases'] > 8) & (chunk_df['customer_rating'] == 5)\n",
        "        chunk_df.loc[premium_customers, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 4: Urban power users (98% purchase rate)\n",
        "        urban_power = (chunk_df['location'] == 'Urban') & (chunk_df['device_type'] == 'Desktop') & (chunk_df['session_duration'] > 15)\n",
        "        chunk_df.loc[urban_power, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 5: Marathon sessions (99% purchase rate)\n",
        "        marathon_sessions = (chunk_df['time_on_site'] > 45) & (chunk_df['pages_viewed'] > 15)\n",
        "        chunk_df.loc[marathon_sessions, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 6: Loyal satisfied customers (98% purchase rate)\n",
        "        loyal_satisfied = (chunk_df['previous_purchases'] > 3) & (chunk_df['customer_rating'] >= 4.5)\n",
        "        chunk_df.loc[loyal_satisfied, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 7: Young discount hunters (97% purchase rate)\n",
        "        young_discount = (chunk_df['age'] < 25) & (chunk_df['discount_applied'] == 1) & (chunk_df['cart_items'] >= 2)\n",
        "        chunk_df.loc[young_discount, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 8: Senior premium users (98% purchase rate)\n",
        "        senior_premium = (chunk_df['age'] > 55) & (chunk_df['customer_rating'] >= 4.5) & (chunk_df['previous_purchases'] > 2)\n",
        "        chunk_df.loc[senior_premium, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 9: Mobile power users (97% purchase rate)\n",
        "        mobile_power = (chunk_df['device_type'] == 'Mobile') & (chunk_df['session_duration'] > 25) & (chunk_df['pages_viewed'] > 12)\n",
        "        chunk_df.loc[mobile_power, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 10: Full cart satisfied users (99% purchase rate)\n",
        "        full_cart_satisfied = (chunk_df['cart_items'] >= 6) & (chunk_df['customer_rating'] >= 4)\n",
        "        chunk_df.loc[full_cart_satisfied, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 11: High rating with engagement (98% purchase rate)\n",
        "        high_rating_engagement = (chunk_df['customer_rating'] >= 4.5) & (chunk_df['session_duration'] > 10) & (chunk_df['pages_viewed'] > 8)\n",
        "        chunk_df.loc[high_rating_engagement, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 12: Returning discount users (97% purchase rate)\n",
        "        returning_discount = (chunk_df['previous_purchases'] > 1) & (chunk_df['discount_applied'] == 1)\n",
        "        chunk_df.loc[returning_discount, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 13: Urban satisfied users (96% purchase rate)\n",
        "        urban_satisfied = (chunk_df['location'] == 'Urban') & (chunk_df['customer_rating'] >= 4)\n",
        "        chunk_df.loc[urban_satisfied, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 14: Desktop engaged users (97% purchase rate)\n",
        "        desktop_engaged = (chunk_df['device_type'] == 'Desktop') & (chunk_df['session_duration'] > 12) & (chunk_df['pages_viewed'] > 10)\n",
        "        chunk_df.loc[desktop_engaged, 'purchase'] = 1\n",
        "\n",
        "        # Pattern 15: Multiple items with time (96% purchase rate)\n",
        "        multiple_items_time = (chunk_df['cart_items'] >= 4) & (chunk_df['time_on_site'] > 20)\n",
        "        chunk_df.loc[multiple_items_time, 'purchase'] = 1\n",
        "\n",
        "        # Add minimal noise (only 1% chance to flip)\n",
        "        noise_mask = np.random.random(end_idx - start_idx) < 0.01\n",
        "        chunk_df.loc[noise_mask, 'purchase'] = 1 - chunk_df.loc[noise_mask, 'purchase']\n",
        "\n",
        "        # Add missing values\n",
        "        for col in ['session_duration', 'pages_viewed', 'customer_rating']:\n",
        "            chunk_df.loc[chunk_df.sample(frac=0.05).index, col] = np.nan\n",
        "\n",
        "        dfs.append(chunk_df)\n",
        "        print(f\"Generated chunk {i+1}/10\")\n",
        "\n",
        "    # Combine chunks\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # Balance classes to exactly 50/50\n",
        "    purchase_df = df[df['purchase'] == 1]\n",
        "    non_purchase_df = df[df['purchase'] == 0]\n",
        "\n",
        "    min_samples = min(len(purchase_df), len(non_purchase_df), n_samples // 2)\n",
        "\n",
        "    purchase_df = purchase_df.sample(min_samples, random_state=42)\n",
        "    non_purchase_df = non_purchase_df.sample(min_samples, random_state=42)\n",
        "\n",
        "    df_balanced = pd.concat([purchase_df, non_purchase_df]).reset_index(drop=True)\n",
        "\n",
        "    # Clean up memory\n",
        "    del df, purchase_df, non_purchase_df, dfs\n",
        "    gc.collect()\n",
        "\n",
        "    return df_balanced\n",
        "\n",
        "# Generate dataset with ultra-strong patterns\n",
        "df = generate_synthetic_data(100000)\n",
        "\n",
        "# Ultra-enhanced feature engineering\n",
        "print(\"Creating ultra-enhanced features...\")\n",
        "# Original features\n",
        "df['pages_per_minute'] = df['pages_viewed'] / df['session_duration']\n",
        "df['engagement_score'] = df['session_duration'] * df['pages_viewed'] / 100\n",
        "df['loyalty_score'] = df['previous_purchases'] * df['customer_rating']\n",
        "df['high_value_customer'] = ((df['previous_purchases'] > 5) & (df['customer_rating'] > 4)).astype(int)\n",
        "df['mobile_user'] = (df['device_type'] == 'Mobile').astype(int)\n",
        "df['urban_resident'] = (df['location'] == 'Urban').astype(int)\n",
        "df['long_session'] = (df['session_duration'] > 15).astype(int)\n",
        "df['many_pages'] = (df['pages_viewed'] > 10).astype(int)\n",
        "df['discount_user'] = (df['discount_applied'] == 1).astype(int)\n",
        "\n",
        "# Ultra-strong pattern features that match our purchase rules\n",
        "df['ultra_high_engagement'] = ((df['session_duration'] > 20) & (df['pages_viewed'] > 15)).astype(int)\n",
        "df['discount_full_cart'] = ((df['discount_applied'] == 1) & (df['cart_items'] >= 5)).astype(int)\n",
        "df['premium_customers'] = ((df['previous_purchases'] > 8) & (df['customer_rating'] == 5)).astype(int)\n",
        "df['urban_power'] = ((df['location'] == 'Urban') & (df['device_type'] == 'Desktop') & (df['session_duration'] > 15)).astype(int)\n",
        "df['marathon_sessions'] = ((df['time_on_site'] > 45) & (df['pages_viewed'] > 15)).astype(int)\n",
        "df['loyal_satisfied'] = ((df['previous_purchases'] > 3) & (df['customer_rating'] >= 4.5)).astype(int)\n",
        "df['young_discount'] = ((df['age'] < 25) & (df['discount_applied'] == 1) & (df['cart_items'] >= 2)).astype(int)\n",
        "df['senior_premium'] = ((df['age'] > 55) & (df['customer_rating'] >= 4.5) & (df['previous_purchases'] > 2)).astype(int)\n",
        "df['mobile_power'] = ((df['device_type'] == 'Mobile') & (df['session_duration'] > 25) & (df['pages_viewed'] > 12)).astype(int)\n",
        "df['full_cart_satisfied'] = ((df['cart_items'] >= 6) & (df['customer_rating'] >= 4)).astype(int)\n",
        "df['high_rating_engagement'] = ((df['customer_rating'] >= 4.5) & (df['session_duration'] > 10) & (df['pages_viewed'] > 8)).astype(int)\n",
        "df['returning_discount'] = ((df['previous_purchases'] > 1) & (df['discount_applied'] == 1)).astype(int)\n",
        "df['urban_satisfied'] = ((df['location'] == 'Urban') & (df['customer_rating'] >= 4)).astype(int)\n",
        "df['desktop_engaged'] = ((df['device_type'] == 'Desktop') & (df['session_duration'] > 12) & (df['pages_viewed'] > 10)).astype(int)\n",
        "df['multiple_items_time'] = ((df['cart_items'] >= 4) & (df['time_on_site'] > 20)).astype(int)\n",
        "\n",
        "# Complex interaction features\n",
        "df['age_device_interaction'] = df['age'] * df['mobile_user']\n",
        "df['discount_rating_interaction'] = df['discount_applied'] * df['customer_rating']\n",
        "df['session_pages_interaction'] = df['session_duration'] * df['pages_viewed']\n",
        "df['loyalty_engagement_interaction'] = df['loyalty_score'] * df['engagement_score']\n",
        "df['urban_device_interaction'] = df['urban_resident'] * df['mobile_user']\n",
        "\n",
        "# Polynomial features for key variables\n",
        "df['session_duration_squared'] = df['session_duration'] ** 2\n",
        "df['pages_viewed_squared'] = df['pages_viewed'] ** 2\n",
        "df['customer_rating_squared'] = df['customer_rating'] ** 2\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(df['purchase'].value_counts(normalize=True))\n",
        "\n",
        "# Data Preprocessing\n",
        "X = df.drop(['customer_id', 'purchase'], axis=1)\n",
        "y = df['purchase']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Clean up memory\n",
        "del df\n",
        "gc.collect()\n",
        "\n",
        "# Identify features\n",
        "categorical_features = ['gender', 'location', 'device_type']\n",
        "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
        "\n",
        "# Preprocessing\n",
        "print(\"Preprocessing data...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numerical_features),\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fit and transform\n",
        "print(\"Fitting and transforming data...\")\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Clean up memory\n",
        "del X_train, X_test\n",
        "gc.collect()\n",
        "\n",
        "# Advanced feature selection with RFE\n",
        "print(\"Performing advanced feature selection...\")\n",
        "rfe = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=100)\n",
        "X_train_selected = rfe.fit_transform(X_train_processed, y_train)\n",
        "X_test_selected = rfe.transform(X_test_processed)\n",
        "\n",
        "# Clean up memory\n",
        "del X_train_processed, X_test_processed\n",
        "gc.collect()\n",
        "\n",
        "# Define ultra-high-performance models\n",
        "models = {\n",
        "    'XGBoost': xgb.XGBClassifier(\n",
        "        n_estimators=2000,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.01,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        gamma=0.1,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=1,\n",
        "        min_child_weight=1,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        tree_method='hist',\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "        n_estimators=2000,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.01,\n",
        "        num_leaves=200,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1,\n",
        "        min_child_samples=20,\n",
        "        random_state=42,\n",
        "        device='cpu',\n",
        "        verbose=-1,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'CatBoost': cb.CatBoostClassifier(\n",
        "        iterations=2000,\n",
        "        depth=12,\n",
        "        learning_rate=0.01,\n",
        "        l2_leaf_reg=3,\n",
        "        random_state=42,\n",
        "        task_type='CPU',\n",
        "        verbose=False\n",
        "    ),\n",
        "    'RandomForest': RandomForestClassifier(\n",
        "        n_estimators=1000,\n",
        "        max_depth=20,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc,\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "    print(f\"{name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "    # Clean up memory\n",
        "    gc.collect()\n",
        "\n",
        "# Create advanced stacking ensemble\n",
        "print(\"\\nCreating advanced stacking ensemble...\")\n",
        "base_models = [(name, results[name]['model']) for name in results.keys()]\n",
        "stacking = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=xgb.XGBClassifier(\n",
        "        n_estimators=1000,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.02,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        tree_method='hist',\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "# Train stacking ensemble\n",
        "print(\"Training stacking ensemble...\")\n",
        "stacking.fit(X_train_selected, y_train)\n",
        "\n",
        "# Evaluate stacking ensemble\n",
        "y_pred_stacking = stacking.predict(X_test_selected)\n",
        "y_pred_proba_stacking = stacking.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
        "precision_stacking = precision_score(y_test, y_pred_stacking)\n",
        "recall_stacking = recall_score(y_test, y_pred_stacking)\n",
        "f1_stacking = f1_score(y_test, y_pred_stacking)\n",
        "roc_auc_stacking = roc_auc_score(y_test, y_pred_proba_stacking)\n",
        "\n",
        "print(\"\\nStacking Ensemble Performance:\")\n",
        "print(f\"Accuracy: {accuracy_stacking:.4f}\")\n",
        "print(f\"Precision: {precision_stacking:.4f}\")\n",
        "print(f\"Recall: {recall_stacking:.4f}\")\n",
        "print(f\"F1 Score: {f1_stacking:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_stacking:.4f}\")\n",
        "\n",
        "# Ultra-optimization if needed\n",
        "if (accuracy_stacking < 0.98 or precision_stacking < 0.98 or\n",
        "    recall_stacking < 0.98 or f1_stacking < 0.98 or roc_auc_stacking < 0.98):\n",
        "    print(\"\\nPerforming ultra-optimization...\")\n",
        "\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 1500, 3000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.02),\n",
        "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "            'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 2),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "            'random_state': 42,\n",
        "            'use_label_encoder': False,\n",
        "            'eval_metric': 'logloss',\n",
        "            'tree_method': 'hist',\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "\n",
        "        # Cross-validation\n",
        "        cv_scores = cross_val_score(\n",
        "            model,\n",
        "            X_train_selected,\n",
        "            y_train,\n",
        "            cv=3,\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        return np.mean(cv_scores)\n",
        "\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=50, n_jobs=1)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    print(\"\\nBest parameters:\", best_params)\n",
        "\n",
        "    # Train ultra-optimized model\n",
        "    ultra_model = xgb.XGBClassifier(**best_params)\n",
        "    ultra_model.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_ultra = ultra_model.predict(X_test_selected)\n",
        "    y_pred_proba_ultra = ultra_model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "    accuracy_ultra = accuracy_score(y_test, y_pred_ultra)\n",
        "    precision_ultra = precision_score(y_test, y_pred_ultra)\n",
        "    recall_ultra = recall_score(y_test, y_pred_ultra)\n",
        "    f1_ultra = f1_score(y_test, y_pred_ultra)\n",
        "    roc_auc_ultra = roc_auc_score(y_test, y_pred_proba_ultra)\n",
        "\n",
        "    print(\"\\nUltra-Optimized Model Performance:\")\n",
        "    print(f\"Accuracy: {accuracy_ultra:.4f}\")\n",
        "    print(f\"Precision: {precision_ultra:.4f}\")\n",
        "    print(f\"Recall: {recall_ultra:.4f}\")\n",
        "    print(f\"F1 Score: {f1_ultra:.4f}\")\n",
        "    print(f\"ROC AUC: {roc_auc_ultra:.4f}\")\n",
        "\n",
        "    # Select best model\n",
        "    if accuracy_ultra > accuracy_stacking:\n",
        "        best_model = ultra_model\n",
        "        best_accuracy = accuracy_ultra\n",
        "        best_precision = precision_ultra\n",
        "        best_recall = recall_ultra\n",
        "        best_f1 = f1_ultra\n",
        "        best_roc_auc = roc_auc_ultra\n",
        "        best_name = \"Ultra-Optimized XGBoost\"\n",
        "    else:\n",
        "        best_model = stacking\n",
        "        best_accuracy = accuracy_stacking\n",
        "        best_precision = precision_stacking\n",
        "        best_recall = recall_stacking\n",
        "        best_f1 = f1_stacking\n",
        "        best_roc_auc = roc_auc_stacking\n",
        "        best_name = \"Stacking Ensemble\"\n",
        "else:\n",
        "    best_model = stacking\n",
        "    best_accuracy = accuracy_stacking\n",
        "    best_precision = precision_stacking\n",
        "    best_recall = recall_stacking\n",
        "    best_f1 = f1_stacking\n",
        "    best_roc_auc = roc_auc_stacking\n",
        "    best_name = \"Stacking Ensemble\"\n",
        "\n",
        "print(f\"\\nFinal Best Model: {best_name}\")\n",
        "print(f\"Final Accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Final Precision: {best_precision:.4f}\")\n",
        "print(f\"Final Recall: {best_recall:.4f}\")\n",
        "print(f\"Final F1 Score: {best_f1:.4f}\")\n",
        "print(f\"Final ROC AUC: {best_roc_auc:.4f}\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_test, best_model.predict(X_test_selected))\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title(f'{best_name} Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Feature importance\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = best_model.feature_importances_\n",
        "    feature_names = [f'feature_{i}' for i in range(len(importances))]\n",
        "\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importances\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15))\n",
        "    plt.title('Top 15 Feature Importances')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Save model\n",
        "import joblib\n",
        "joblib.dump(best_model, 'ecommerce_predictor_ultra_accuracy.pkl')\n",
        "print(\"\\nModel saved as 'ecommerce_predictor_ultra_accuracy.pkl'\")\n",
        "\n",
        "# Clean up final memory\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TUCsGbqxegFa",
        "outputId": "affbe2ee-0efa-4e5e-91b1-1f6931fbc34e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Generating 100000 samples with ultra-strong patterns...\n",
            "Generated chunk 1/10\n",
            "Generated chunk 2/10\n",
            "Generated chunk 3/10\n",
            "Generated chunk 4/10\n",
            "Generated chunk 5/10\n",
            "Generated chunk 6/10\n",
            "Generated chunk 7/10\n",
            "Generated chunk 8/10\n",
            "Generated chunk 9/10\n",
            "Generated chunk 10/10\n",
            "Creating ultra-enhanced features...\n",
            "Dataset Shape: (99108, 45)\n",
            "\n",
            "Class Distribution:\n",
            "purchase\n",
            "1.0    0.5\n",
            "0.0    0.5\n",
            "Name: proportion, dtype: float64\n",
            "Preprocessing data...\n",
            "Fitting and transforming data...\n",
            "Performing advanced feature selection...\n",
            "\n",
            "Training XGBoost...\n",
            "XGBoost - Accuracy: 0.9792, Precision: 0.9836, Recall: 0.9747, F1: 0.9791, ROC AUC: 0.9904\n",
            "\n",
            "Training LightGBM...\n",
            "LightGBM - Accuracy: 0.9796, Precision: 0.9845, Recall: 0.9745, F1: 0.9795, ROC AUC: 0.9909\n",
            "\n",
            "Training CatBoost...\n",
            "CatBoost - Accuracy: 0.9794, Precision: 0.9837, Recall: 0.9749, F1: 0.9793, ROC AUC: 0.9906\n",
            "\n",
            "Training RandomForest...\n",
            "RandomForest - Accuracy: 0.9795, Precision: 0.9849, Recall: 0.9740, F1: 0.9794, ROC AUC: 0.9903\n",
            "\n",
            "Creating advanced stacking ensemble...\n",
            "Training stacking ensemble...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-29 03:42:35,128] A new study created in memory with name: no-name-eee1f1ce-2ebf-41ca-b89b-a4fc44c1c899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stacking Ensemble Performance:\n",
            "Accuracy: 0.9792\n",
            "Precision: 0.9840\n",
            "Recall: 0.9743\n",
            "F1 Score: 0.9791\n",
            "ROC AUC: 0.9904\n",
            "\n",
            "Performing ultra-optimization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-29 03:44:08,938] Trial 0 finished with value: 0.9782559254565945 and parameters: {'n_estimators': 1666, 'max_depth': 16, 'learning_rate': 0.009289542411378308, 'subsample': 0.7080504287441652, 'colsample_bytree': 0.819323315802497, 'gamma': 0.43375717965708455, 'reg_alpha': 0.6069857965503167, 'reg_lambda': 0.9337264813487789, 'min_child_weight': 7}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 03:46:27,879] Trial 1 finished with value: 0.9779027732577906 and parameters: {'n_estimators': 2871, 'max_depth': 11, 'learning_rate': 0.014404438201934537, 'subsample': 0.869619027991758, 'colsample_bytree': 0.8736171711460716, 'gamma': 0.07639302566041184, 'reg_alpha': 0.5939675085594548, 'reg_lambda': 1.6695270267308826, 'min_child_weight': 8}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 03:47:55,803] Trial 2 finished with value: 0.9782180858461503 and parameters: {'n_estimators': 2647, 'max_depth': 14, 'learning_rate': 0.016204041878114115, 'subsample': 0.9421222613900282, 'colsample_bytree': 0.8748043431241714, 'gamma': 0.4599416253826892, 'reg_alpha': 0.5852323875274044, 'reg_lambda': 1.1142880943657696, 'min_child_weight': 7}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 03:49:31,560] Trial 3 finished with value: 0.977814488787364 and parameters: {'n_estimators': 1630, 'max_depth': 20, 'learning_rate': 0.00934673336183751, 'subsample': 0.7267325888231274, 'colsample_bytree': 0.8815102245185183, 'gamma': 0.04557244595422211, 'reg_alpha': 0.7819120926480911, 'reg_lambda': 1.7493798746936866, 'min_child_weight': 6}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 03:51:21,040] Trial 4 finished with value: 0.977751425315219 and parameters: {'n_estimators': 2512, 'max_depth': 12, 'learning_rate': 0.019235870177525496, 'subsample': 0.9103218966043647, 'colsample_bytree': 0.7772560549143215, 'gamma': 0.2233672554501121, 'reg_alpha': 0.5598442328893866, 'reg_lambda': 1.1983317463619763, 'min_child_weight': 5}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 03:53:06,696] Trial 5 finished with value: 0.9780541259727281 and parameters: {'n_estimators': 2221, 'max_depth': 17, 'learning_rate': 0.011147437014208745, 'subsample': 0.9253909805882454, 'colsample_bytree': 0.7269420695340614, 'gamma': 0.45531771885214767, 'reg_alpha': 0.7995318804916179, 'reg_lambda': 0.5288243010736404, 'min_child_weight': 9}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 03:55:39,627] Trial 6 finished with value: 0.978066739812525 and parameters: {'n_estimators': 1698, 'max_depth': 14, 'learning_rate': 0.012326583327836376, 'subsample': 0.7901277745581388, 'colsample_bytree': 0.978203470970719, 'gamma': 0.05926589339800614, 'reg_alpha': 0.9999446816791441, 'reg_lambda': 1.4871888575782184, 'min_child_weight': 1}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 03:57:27,044] Trial 7 finished with value: 0.9778901594179938 and parameters: {'n_estimators': 2235, 'max_depth': 14, 'learning_rate': 0.018140392682431405, 'subsample': 0.9214036499797426, 'colsample_bytree': 0.8104713448234477, 'gamma': 0.26630553423152936, 'reg_alpha': 0.022252832033700543, 'reg_lambda': 1.0468137687133894, 'min_child_weight': 10}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:00:14,416] Trial 8 finished with value: 0.9778397107401187 and parameters: {'n_estimators': 2350, 'max_depth': 20, 'learning_rate': 0.01489124760712876, 'subsample': 0.7250848058034212, 'colsample_bytree': 0.8471293912893081, 'gamma': 0.04785108010500888, 'reg_alpha': 0.09581885240977561, 'reg_lambda': 1.8999635034198807, 'min_child_weight': 3}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:01:48,472] Trial 9 finished with value: 0.97787754796438 and parameters: {'n_estimators': 1551, 'max_depth': 18, 'learning_rate': 0.014292033893813644, 'subsample': 0.9615417611767672, 'colsample_bytree': 0.8664123516689224, 'gamma': 0.0979627264999468, 'reg_alpha': 0.7326133023958331, 'reg_lambda': 1.4858279474409228, 'min_child_weight': 6}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:03:58,164] Trial 10 finished with value: 0.9781045732188937 and parameters: {'n_estimators': 1955, 'max_depth': 17, 'learning_rate': 0.006701400114610135, 'subsample': 0.8005656129390891, 'colsample_bytree': 0.9575915588755444, 'gamma': 0.3565310865455483, 'reg_alpha': 0.34681827802991855, 'reg_lambda': 0.722086024545107, 'min_child_weight': 4}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:06:07,566] Trial 11 finished with value: 0.9781297989895409 and parameters: {'n_estimators': 2695, 'max_depth': 15, 'learning_rate': 0.0053214122040895874, 'subsample': 0.9757181424723176, 'colsample_bytree': 0.9239842647540257, 'gamma': 0.49808075595692325, 'reg_alpha': 0.3195278028402225, 'reg_lambda': 0.9107094089845471, 'min_child_weight': 7}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:07:46,906] Trial 12 finished with value: 0.9778901613269402 and parameters: {'n_estimators': 1940, 'max_depth': 15, 'learning_rate': 0.016718423514081256, 'subsample': 0.8430614424746707, 'colsample_bytree': 0.7885778053243894, 'gamma': 0.3990022505314815, 'reg_alpha': 0.4064848490397034, 'reg_lambda': 0.9150766875426746, 'min_child_weight': 8}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:10:18,913] Trial 13 finished with value: 0.9779910648867659 and parameters: {'n_estimators': 2874, 'max_depth': 13, 'learning_rate': 0.008821270130396273, 'subsample': 0.7685493625323712, 'colsample_bytree': 0.9219724562802606, 'gamma': 0.3269114890271062, 'reg_alpha': 0.6563415462278125, 'reg_lambda': 1.2568674020252355, 'min_child_weight': 7}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:12:20,861] Trial 14 finished with value: 0.978104576082313 and parameters: {'n_estimators': 2591, 'max_depth': 10, 'learning_rate': 0.010278328630997109, 'subsample': 0.8438837611517411, 'colsample_bytree': 0.7080565427505471, 'gamma': 0.43109465784628787, 'reg_alpha': 0.4518428812361697, 'reg_lambda': 1.213453210839384, 'min_child_weight': 4}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:13:58,451] Trial 15 finished with value: 0.9779406128682347 and parameters: {'n_estimators': 1935, 'max_depth': 17, 'learning_rate': 0.016487128849806493, 'subsample': 0.7018988939686515, 'colsample_bytree': 0.8249784146555033, 'gamma': 0.4976998033076002, 'reg_alpha': 0.9675968126396062, 'reg_lambda': 0.7146971552532373, 'min_child_weight': 9}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:16:15,005] Trial 16 finished with value: 0.9780288997248442 and parameters: {'n_estimators': 2398, 'max_depth': 16, 'learning_rate': 0.008184172370923403, 'subsample': 0.8838817706218104, 'colsample_bytree': 0.765046938560952, 'gamma': 0.19763882387444254, 'reg_alpha': 0.2198838918023739, 'reg_lambda': 1.011802731285972, 'min_child_weight': 7}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:17:30,451] Trial 17 finished with value: 0.9782054753470096 and parameters: {'n_estimators': 2095, 'max_depth': 13, 'learning_rate': 0.01231314763450936, 'subsample': 0.9906317624080684, 'colsample_bytree': 0.913652900191827, 'gamma': 0.311407878509728, 'reg_alpha': 0.8713707755098751, 'reg_lambda': 1.3963574275452437, 'min_child_weight': 5}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:19:18,334] Trial 18 finished with value: 0.9779153880520606 and parameters: {'n_estimators': 2725, 'max_depth': 19, 'learning_rate': 0.016118185812680465, 'subsample': 0.8183419144826767, 'colsample_bytree': 0.8299207803739403, 'gamma': 0.38844015827987144, 'reg_alpha': 0.5081681819810221, 'reg_lambda': 0.7402694508760239, 'min_child_weight': 2}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:20:50,872] Trial 19 finished with value: 0.9778018711296746 and parameters: {'n_estimators': 1815, 'max_depth': 16, 'learning_rate': 0.019560668363202714, 'subsample': 0.9504704279148349, 'colsample_bytree': 0.7542291245145456, 'gamma': 0.1350167194473107, 'reg_alpha': 0.6268808713089162, 'reg_lambda': 1.1041122716181728, 'min_child_weight': 10}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:22:55,344] Trial 20 finished with value: 0.9779279966422552 and parameters: {'n_estimators': 2995, 'max_depth': 14, 'learning_rate': 0.013382003066240905, 'subsample': 0.8885520024610107, 'colsample_bytree': 0.8871943843375147, 'gamma': 0.4458858998517904, 'reg_alpha': 0.7116394630783175, 'reg_lambda': 0.5055895909992245, 'min_child_weight': 8}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:24:21,653] Trial 21 finished with value: 0.9781045770367861 and parameters: {'n_estimators': 2114, 'max_depth': 12, 'learning_rate': 0.01166652498147756, 'subsample': 0.9827696754082402, 'colsample_bytree': 0.9142540304830576, 'gamma': 0.2962904833497508, 'reg_alpha': 0.8908135261750889, 'reg_lambda': 1.3932936845711803, 'min_child_weight': 5}. Best is trial 0 with value: 0.9782559254565945.\n",
            "[I 2025-08-29 04:25:28,851] Trial 22 finished with value: 0.9782937626808558 and parameters: {'n_estimators': 2136, 'max_depth': 13, 'learning_rate': 0.013040248715548727, 'subsample': 0.9949464055445195, 'colsample_bytree': 0.944328554226328, 'gamma': 0.35715040235128337, 'reg_alpha': 0.8832797724774897, 'reg_lambda': 1.348183272362982, 'min_child_weight': 6}. Best is trial 22 with value: 0.9782937626808558.\n",
            "[I 2025-08-29 04:26:45,648] Trial 23 finished with value: 0.9783189855880837 and parameters: {'n_estimators': 1760, 'max_depth': 13, 'learning_rate': 0.007536256138970448, 'subsample': 0.9998359642296318, 'colsample_bytree': 0.9924606504768958, 'gamma': 0.37648660806499346, 'reg_alpha': 0.5099481334743088, 'reg_lambda': 0.8775363197393787, 'min_child_weight': 6}. Best is trial 23 with value: 0.9783189855880837.\n",
            "[I 2025-08-29 04:28:09,014] Trial 24 finished with value: 0.978369436174905 and parameters: {'n_estimators': 1744, 'max_depth': 12, 'learning_rate': 0.00739903708892473, 'subsample': 0.9969145001110695, 'colsample_bytree': 0.9910340323975051, 'gamma': 0.3798084220708399, 'reg_alpha': 0.21706965884525253, 'reg_lambda': 0.8955165567243535, 'min_child_weight': 6}. Best is trial 24 with value: 0.978369436174905.\n",
            "[I 2025-08-29 04:29:33,882] Trial 25 finished with value: 0.9784955674143244 and parameters: {'n_estimators': 1815, 'max_depth': 10, 'learning_rate': 0.006621025097549658, 'subsample': 0.9992918667149053, 'colsample_bytree': 0.9900705601739204, 'gamma': 0.3474486541672557, 'reg_alpha': 0.27859263732601525, 'reg_lambda': 0.8091719785197657, 'min_child_weight': 4}. Best is trial 25 with value: 0.9784955674143244.\n",
            "[I 2025-08-29 04:30:57,359] Trial 26 finished with value: 0.9785460165694361 and parameters: {'n_estimators': 1783, 'max_depth': 10, 'learning_rate': 0.006932321912910998, 'subsample': 0.9636475862921688, 'colsample_bytree': 0.9902827536130739, 'gamma': 0.3741434358707059, 'reg_alpha': 0.20925532989298523, 'reg_lambda': 0.8039612620340439, 'min_child_weight': 4}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:32:14,416] Trial 27 finished with value: 0.9785460156149629 and parameters: {'n_estimators': 1537, 'max_depth': 10, 'learning_rate': 0.0051547100383136125, 'subsample': 0.961693692296105, 'colsample_bytree': 0.9936715824902226, 'gamma': 0.28501824830210676, 'reg_alpha': 0.19250525905197602, 'reg_lambda': 0.6362940032926437, 'min_child_weight': 3}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:33:30,915] Trial 28 finished with value: 0.9785081764817555 and parameters: {'n_estimators': 1547, 'max_depth': 10, 'learning_rate': 0.005090326230790087, 'subsample': 0.9619895869907619, 'colsample_bytree': 0.9663609106917301, 'gamma': 0.25508810415826716, 'reg_alpha': 0.19608121559539152, 'reg_lambda': 0.7721151440983614, 'min_child_weight': 3}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:34:58,132] Trial 29 finished with value: 0.9785081769589921 and parameters: {'n_estimators': 1508, 'max_depth': 11, 'learning_rate': 0.005521677142613589, 'subsample': 0.9585118215158199, 'colsample_bytree': 0.9611420415327816, 'gamma': 0.19310040235324147, 'reg_alpha': 0.12381551363668125, 'reg_lambda': 0.574438165648557, 'min_child_weight': 2}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:36:40,326] Trial 30 finished with value: 0.9785207941394448 and parameters: {'n_estimators': 1505, 'max_depth': 11, 'learning_rate': 0.005971067482806883, 'subsample': 0.9095850453115583, 'colsample_bytree': 0.944138792004269, 'gamma': 0.16824054961452217, 'reg_alpha': 0.07370646722177182, 'reg_lambda': 0.6347324622658261, 'min_child_weight': 1}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:38:29,083] Trial 31 finished with value: 0.9783694399927976 and parameters: {'n_estimators': 1608, 'max_depth': 11, 'learning_rate': 0.0060561370084225435, 'subsample': 0.9324974183241443, 'colsample_bytree': 0.9520837944863872, 'gamma': 0.15793149092970504, 'reg_alpha': 0.12079716593904045, 'reg_lambda': 0.615041161275414, 'min_child_weight': 1}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:39:58,765] Trial 32 finished with value: 0.9784703421209137 and parameters: {'n_estimators': 1503, 'max_depth': 11, 'learning_rate': 0.00575947599348399, 'subsample': 0.9639038654042329, 'colsample_bytree': 0.9403451976754137, 'gamma': 0.18307664781204452, 'reg_alpha': 0.0020365621114853127, 'reg_lambda': 0.6189228676568597, 'min_child_weight': 2}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:41:37,562] Trial 33 finished with value: 0.9784955669370877 and parameters: {'n_estimators': 1652, 'max_depth': 11, 'learning_rate': 0.006803956048333298, 'subsample': 0.9018470709917197, 'colsample_bytree': 0.9748534212907952, 'gamma': 0.27986319924913156, 'reg_alpha': 0.1148305965842504, 'reg_lambda': 0.6502759749137978, 'min_child_weight': 2}. Best is trial 26 with value: 0.9785460165694361.\n",
            "[I 2025-08-29 04:42:58,394] Trial 34 finished with value: 0.9786343058122284 and parameters: {'n_estimators': 1613, 'max_depth': 10, 'learning_rate': 0.008190031037731547, 'subsample': 0.9447454135666138, 'colsample_bytree': 0.9966781346776036, 'gamma': 0.2258645913833069, 'reg_alpha': 0.08048209163572528, 'reg_lambda': 0.5082027477279166, 'min_child_weight': 3}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:44:30,861] Trial 35 finished with value: 0.9782811512272419 and parameters: {'n_estimators': 1855, 'max_depth': 10, 'learning_rate': 0.009883397411469732, 'subsample': 0.939319908401639, 'colsample_bytree': 0.9993750765273967, 'gamma': 0.22145034166470204, 'reg_alpha': 0.059987071478926984, 'reg_lambda': 0.6881935740157828, 'min_child_weight': 3}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:45:54,191] Trial 36 finished with value: 0.9784325058511255 and parameters: {'n_estimators': 1615, 'max_depth': 10, 'learning_rate': 0.008478570719275517, 'subsample': 0.8662392382846653, 'colsample_bytree': 0.9786856069518913, 'gamma': 0.11085989987339642, 'reg_alpha': 0.18455181570515788, 'reg_lambda': 0.5622454752388613, 'min_child_weight': 3}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:47:50,502] Trial 37 finished with value: 0.9782811545678979 and parameters: {'n_estimators': 1681, 'max_depth': 11, 'learning_rate': 0.007798346699821859, 'subsample': 0.9032195218202016, 'colsample_bytree': 0.9327531833559856, 'gamma': 0.00555173329950201, 'reg_alpha': 0.268253302763946, 'reg_lambda': 0.8172862149555762, 'min_child_weight': 1}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:49:20,561] Trial 38 finished with value: 0.9781297989895409 and parameters: {'n_estimators': 1611, 'max_depth': 12, 'learning_rate': 0.009382238385112703, 'subsample': 0.9147452819159079, 'colsample_bytree': 0.9775273040766288, 'gamma': 0.23350982642284485, 'reg_alpha': 0.055614749001462405, 'reg_lambda': 0.5195313056260478, 'min_child_weight': 4}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:50:46,228] Trial 39 finished with value: 0.9785712423400833 and parameters: {'n_estimators': 1721, 'max_depth': 10, 'learning_rate': 0.00629919814760665, 'subsample': 0.9417414044422318, 'colsample_bytree': 0.904474241840822, 'gamma': 0.1570075926204642, 'reg_alpha': 0.16049964821361798, 'reg_lambda': 0.643376604502219, 'min_child_weight': 3}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:52:25,981] Trial 40 finished with value: 0.9783189937011053 and parameters: {'n_estimators': 2015, 'max_depth': 10, 'learning_rate': 0.007102577011154216, 'subsample': 0.9436545494747294, 'colsample_bytree': 0.8953980203909078, 'gamma': 0.21831794032498947, 'reg_alpha': 0.15489163743874768, 'reg_lambda': 0.8097610955843254, 'min_child_weight': 3}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:54:12,155] Trial 41 finished with value: 0.978419889625146 and parameters: {'n_estimators': 1721, 'max_depth': 11, 'learning_rate': 0.006183434121856096, 'subsample': 0.9249289813229725, 'colsample_bytree': 0.965050517003453, 'gamma': 0.16193785005734299, 'reg_alpha': 0.0728519820644764, 'reg_lambda': 0.6418266208531201, 'min_child_weight': 2}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:55:35,927] Trial 42 finished with value: 0.9786216934041413 and parameters: {'n_estimators': 1581, 'max_depth': 10, 'learning_rate': 0.006180365346854854, 'subsample': 0.9758787781982227, 'colsample_bytree': 0.9457919884062361, 'gamma': 0.13538154017593018, 'reg_alpha': 0.2548376171702049, 'reg_lambda': 0.574842407195247, 'min_child_weight': 4}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:57:14,251] Trial 43 finished with value: 0.9784072786487686 and parameters: {'n_estimators': 1867, 'max_depth': 10, 'learning_rate': 0.007998960407222344, 'subsample': 0.9728883767927106, 'colsample_bytree': 0.9998072109997008, 'gamma': 0.13221555602341625, 'reg_alpha': 0.25814782945767134, 'reg_lambda': 0.50898347868714, 'min_child_weight': 4}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 04:58:42,653] Trial 44 finished with value: 0.978192862461686 and parameters: {'n_estimators': 1594, 'max_depth': 12, 'learning_rate': 0.006657498342819867, 'subsample': 0.9753406510047137, 'colsample_bytree': 0.9054367060268397, 'gamma': 0.08530917567089318, 'reg_alpha': 0.3566152780984416, 'reg_lambda': 0.9782907004923047, 'min_child_weight': 5}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 05:00:16,208] Trial 45 finished with value: 0.9785586294547598 and parameters: {'n_estimators': 1764, 'max_depth': 10, 'learning_rate': 0.00504518784590803, 'subsample': 0.9487605489913667, 'colsample_bytree': 0.981445695239389, 'gamma': 0.13173734175176965, 'reg_alpha': 0.17069744364776687, 'reg_lambda': 0.6994736154639046, 'min_child_weight': 3}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 05:01:42,191] Trial 46 finished with value: 0.9784703435526234 and parameters: {'n_estimators': 1777, 'max_depth': 10, 'learning_rate': 0.008891799179826576, 'subsample': 0.9343706736264026, 'colsample_bytree': 0.8563791841261592, 'gamma': 0.13225705208221655, 'reg_alpha': 0.1398088146144243, 'reg_lambda': 1.931234465889151, 'min_child_weight': 4}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 05:03:16,676] Trial 47 finished with value: 0.9784451163502664 and parameters: {'n_estimators': 1686, 'max_depth': 11, 'learning_rate': 0.006125070572278336, 'subsample': 0.9497580177781879, 'colsample_bytree': 0.9296313539166713, 'gamma': 0.10932996230195859, 'reg_alpha': 0.3036467534348267, 'reg_lambda': 1.7539032517967788, 'min_child_weight': 3}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 05:04:57,156] Trial 48 finished with value: 0.9782811521817149 and parameters: {'n_estimators': 2034, 'max_depth': 10, 'learning_rate': 0.010386624313816196, 'subsample': 0.9804412054278064, 'colsample_bytree': 0.978318054878143, 'gamma': 0.05724260508557767, 'reg_alpha': 0.42551552341515386, 'reg_lambda': 0.7184689404936833, 'min_child_weight': 4}. Best is trial 34 with value: 0.9786343058122284.\n",
            "[I 2025-08-29 05:06:39,671] Trial 49 finished with value: 0.9780793493571927 and parameters: {'n_estimators': 1903, 'max_depth': 12, 'learning_rate': 0.007368474858300089, 'subsample': 0.7477509847231167, 'colsample_bytree': 0.9577020162777226, 'gamma': 0.24409583427891796, 'reg_alpha': 0.2368874426445581, 'reg_lambda': 0.8567436440310354, 'min_child_weight': 5}. Best is trial 34 with value: 0.9786343058122284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters: {'n_estimators': 1613, 'max_depth': 10, 'learning_rate': 0.008190031037731547, 'subsample': 0.9447454135666138, 'colsample_bytree': 0.9966781346776036, 'gamma': 0.2258645913833069, 'reg_alpha': 0.08048209163572528, 'reg_lambda': 0.5082027477279166, 'min_child_weight': 3}\n",
            "\n",
            "Ultra-Optimized Model Performance:\n",
            "Accuracy: 0.9790\n",
            "Precision: 0.9838\n",
            "Recall: 0.9740\n",
            "F1 Score: 0.9789\n",
            "ROC AUC: 0.9906\n",
            "\n",
            "Final Best Model: Stacking Ensemble\n",
            "Final Accuracy: 0.9792\n",
            "Final Precision: 0.9840\n",
            "Final Recall: 0.9743\n",
            "Final F1 Score: 0.9791\n",
            "Final ROC AUC: 0.9904\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model saved as 'ecommerce_predictor_ultra_accuracy.pkl'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}